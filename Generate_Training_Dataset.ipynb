{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generator notebook for Magnetic Signal reconstruction\n",
    "\n",
    "This notebook describes explicitly the magnetic field component dataset generator's first version. Because Matlab requests specifics version of python to load its engine, we are using an old python version. Python 2.7 seems to be more stable with the Matlab version I had (R2016b) regarding long-running time and potential data leaks. The versions can be updated easily. I wrote the code allowing it to run on a Python3 environment needing as fewer modifications as possible.\n",
    "\n",
    "I don't recommand to use this Notebook to generate the training set, using a python script is much easier and faster.\n",
    "To generate a .py script from a notebook (.ipynb) run this command:\n",
    "\n",
    "`jupyter nbconvert --to python notebook_name.ipynb`\n",
    "\n",
    "This will generate a python script (with all the comments included) you can run in background using for example:\n",
    "\n",
    "`( nohup python script.py & )` \n",
    "\n",
    "`nohup` launches the script as a background job. If you launch this through `ssh` the job will be killed after you close the session. To avoid that, add parenthesis to run it in a subshell. I recommand using `nohup` to keep trace of what's happening through execution in the nohup file. It can be consulted any time of the execution using `tail -f nohup.out` to access in real time the last written bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "from scipy.io import loadmat\n",
    "from collections import defaultdict\n",
    "from os import system\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')\n",
    "clear = lambda: system('clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python allows us to run Matlab functions in background and retrieve their output. The Output format will, of course, be specific, for example, a `float ` output coming out from a Matlab function will be interpreted as `matlab.double` for Linux and `matlab.mlarray.double` for Windows.\n",
    "All of these can be reformatted to native python variables. We now can call Matlab functions from the `eng` object. \n",
    "\n",
    "__*Only functions referenced in the installed Matlab's path can be called from the engine*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab() #starting and storing the matlab engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables instantiation\n",
    "The below cell instantiates all the variables we will use in the execution. Working with this amount of `public` variables is not a good practice. But for development purpose and easier debugging time (Jupyter doesn't have any debugger natively), instantiating them as `public` allows us to access them at any time in the process easily. One improvement would be to install an external Debugging plugin to Jupyter-lab and transpose all the `public` variables to `private`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quietDays = np.array(eng.quiet()) # we retreive the output of the `quiet()` matlab function, convert it as `numpy.array` and finally store it.\n",
    "\n",
    "#Instantiate the starting date\n",
    "year = 2010\n",
    "month = 1\n",
    "day = 1\n",
    "hour = 0\n",
    "minute = 0\n",
    "second = 0\n",
    "\n",
    "# We want 3 days of data retreived, because we are shifting values according to the latitude to create local time matrices, \n",
    "# we need one day before and one day after to make enough space for the shift in both directions.\n",
    "\n",
    "numberOfDaysWithData = 3\n",
    "numberOfDaysWithDataDate = datetime.timedelta(days=numberOfDaysWithData) #create a timedelta equals to the numberOfDaysWithData to calculate the endDate of the matrix \n",
    "\n",
    "# Instantiate the dates, startDateBase corresponds to the absolute starting date, \n",
    "# startDate and endDate will be modified through the execution, one day more each epoch. \n",
    "startDate = datetime.datetime(year, month, day, hour, minute, second)\n",
    "endDate = startDate+numberOfDaysWithDataDate\n",
    "startDateBase = startDate\n",
    "\n",
    "# Mandatory to create valid dates for Matlab, the engine only reads list() objects as date input \n",
    "startDateMatlab = [startDate.year, startDate.month, startDate.day, startDate.hour, startDate.minute, startDate.second]\n",
    "endDateMatlab = [endDate.year, endDate.month, endDate.day, endDate.hour, endDate.minute, endDate.second]\n",
    "\n",
    "\n",
    "stationsWithNoData = [] # list of stations without data for the given date\n",
    "stationsNonexistentInFolder = [] # if the station loaded in the station.mat file doesn't exist in the folder, we list it here\n",
    "stationsOut = dict() # contains all the information related to their station name, stores all the output of Matlab's indices_alpha\n",
    "stationIndicatorVariation = defaultdict(list) # split of stationsOut, contains the values from indices_alpha but for one single indice (the one we chose to work with)\n",
    "\n",
    "# Setting up the paths (relative path obviously, needs to be changed if the folder structure changes)\n",
    "trainingDatasetPath = \"../TrainingDataset\"\n",
    "# Windows : \"D:/IRAP/TrainingDataset\"\n",
    "# Linux : \"../TrainingDataset\"\n",
    "\n",
    "# load the stations list\n",
    "# WINDOWS\n",
    "# mat = loadmat(\"D:/IRAP/dir.indices/station.mat\")\n",
    "# LINUX\n",
    "mat = loadmat(\"../../../../opt/dir.indices/station.mat\")\n",
    "\n",
    "# store the \"station\" column values from the .mat file \n",
    "stationsList = mat.get(\"station\", \"none\")[0]\n",
    "allStationCodes=np.array([])\n",
    "allStationLatgeos=np.array([])\n",
    "\n",
    "# store in separate arrays all the stations code (clf, aae...) and their geographic latitudes\n",
    "for x in stationsList:\n",
    "    allStationCodes=np.append(allStationCodes,x[1][0])\n",
    "    allStationLatgeos=np.append(allStationLatgeos,x[3][0])\n",
    "\n",
    "# within which latitude boundaries do we want our matrix\n",
    "latMin=30\n",
    "latMax=56\n",
    "    \n",
    "stationIndicatorRatioVariation = defaultdict(list) # dictionary assigning to each station name it's weight\n",
    "numberOfMinutesNeededInTheTimeStamp=0 # the number of minutes within numberOfDaysWithData\n",
    "timeBetweenValues=0 # of many minutes do we want between each values for one station (increases consequently the computing time)\n",
    "numberOfValues=0 # of many values retreived for one station\n",
    "indicatorVariationArray = np.array([]) # the array containing all the magnetic indices for numberOfDaysWithData and each station in UTC\n",
    "indicatorVariationArrayLocalTime = np.array([]) # the array containing all the magnetic indices for numberOfDaysWithData and each station in local time\n",
    "normalized01StationIndicatorVariation = defaultdict(list) # same as indicatorVariationArrayLocalTime, but normalized within given bounds\n",
    "maxValueinDataset=0 # the maximum value in the current matrix\n",
    "minValueinDataset=0 # the minimum value in the current matrix\n",
    "ReconstructedArray = np.array([]) # same as normalized01StationIndicatorVariation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenerateTrainingSet()\n",
    "\"main\" function which launches all the others and save the generated arrays as .npy files. (.npy files store arrays in binary and are readable by `numpy`, processing them is way faster than the usual `panda` datasets and the storing space is significantly shorten.\n",
    "\n",
    "The `def` starts a loop that lasts equally to the `dataSetSize` we want. It increments at each loop one day to the absolute starting date, requests Matlab on the new time bound, transforsms the output in arrays, normalizes them and finally stores everyting.\n",
    "\n",
    "#### Storing format\n",
    "We store three arrays. The two first of shape (24,144), 24 degrees in latitude for 144 values each. The third array of shape (7, ) storing all the informations we need for the current day. All arrays gathered we get an array of shape (3, ) symbolising an array of three arrays.\n",
    "\n",
    "|Ground truth|Machine learning reconstruction|Infos|\n",
    "|:-:|:-:|:-:|\n",
    "|Absolute ground truth got from Matlab without any modification|The Ground truth with all nan values filled with Polynomial Regression|Informations about the current matrix|\n",
    "|(24,144)|(24,144)|(7, )|\n",
    "\n",
    "The information array is constituted of:\n",
    "\n",
    "|Date|Max latitude|Min latitude|Max value|Min value|Days|isQuiet|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Date of the current matrix stored as datetime object|Latitude degree corresponding to the last index of the array|Latitude degree corresponding to the first index of the array|Maximum value in the matrix (in nT)|Minimum value in the matrix (in nT)|Number of days in the matrix|Is the current matrix conrresponding to a quiet day?|\n",
    "|datetime.datetime|Integer|Integer|Float|Float|Integer|Bool|\n",
    "\n",
    "Note that we have to load these arrays using:\n",
    "```python\n",
    "array = np.load(\"path_to_array/array.npy\", allow_pickle=True, encoding=\"latin1\")\n",
    "```\n",
    "`allow_pickle=True` and `encoding=\"latin1\"` allows us to load `object` values into `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTrainingSet():\n",
    "    global year\n",
    "    global month\n",
    "    global day\n",
    "    global startDate\n",
    "    global endDate\n",
    "    global startDateMatlab\n",
    "    global endDateMatlab\n",
    "    global stationsWithNoData\n",
    "    global stationsNonexistentInFolder\n",
    "    global stationsOut\n",
    "    global indicatorVariationArrayLocalTime\n",
    "    global numberOfDaysWithData\n",
    "    \n",
    "    index=0\n",
    "    dataSetSize = 6500\n",
    "    matrixDurationDays = numberOfDaysWithData-2\n",
    "    isQuietDay = False\n",
    "    for i in range(0,dataSetSize,matrixDurationDays):\n",
    "        startDate = startDateBase+datetime.timedelta(days=i)\n",
    "        endDate = startDate+datetime.timedelta(days=numberOfDaysWithData)\n",
    "        startDateMatlab = [startDate.year, startDate.month, startDate.day, 0, 0, 0]\n",
    "        endDateMatlab = [endDate.year, endDate.month, endDate.day, 0, 0, 0]\n",
    "        sys.stdout.flush() # flushes the verbose output allowing us to read everything on time if we launch the script in a nohup subshell \n",
    "        RequestMatlab()\n",
    "        MakeStationIndicatorVariation()\n",
    "        ManuallyNormalizeData01()      \n",
    "        makeIndicatorVariationArray()\n",
    "        ResizeForPlot()\n",
    "#         RemoveDefectiveStation(indicatorVariationArrayLocalTime)\n",
    "        ReconstructedArray = PredictIndicatorForAllLatitudes(indicatorVariationArrayLocalTime)\n",
    "        for a in quietDays:\n",
    "            compare = np.array(startDateMatlab) == a\n",
    "            if compare.all(): \n",
    "                isQuietDay = True\n",
    "                break\n",
    "            else: \n",
    "                isQuietDay = False \n",
    "        infosArray = np.array([startDate, latMax, latMin, maxValueinDataset, minValueinDataset, matrixDurationDays, isQuietDay])\n",
    "        FinalArray = np.array([indicatorVariationArrayLocalTime, ReconstructedArray, infosArray])\n",
    "        np.save(\"{}/x_train/Y2_{}\".format(trainingDatasetPath, index), FinalArray)\n",
    "        print(\"Matrix saved for date: {}\".format(startDate))\n",
    "        print(\"Sample {} out of {}\".format(i, dataSetSize))\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "availableStations = [\"frd\", \"frn\", \"new\", \"mea\", \"bsl\", \"tuc\", \"ott\", \"bou\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6711577]\n",
      "[-2.5488434]\n",
      "[-2.0817437]\n",
      "[-1.3211565]\n",
      "[-2.460254]\n",
      "[-2.6581156]\n",
      "[-1.3402325]\n",
      "[-2.8003714]\n"
     ]
    }
   ],
   "source": [
    "for station in availableStations:\n",
    "    print(stationIndicatorVariation[station][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frd\n",
      "frn\n",
      "new\n",
      "mea\n",
      "bsl\n",
      "tuc\n",
      "ott\n",
      "bou\n",
      "Matrix saved for date: 2010-01-01 00:00:00\n",
      "Sample 0 out of 6500\n",
      "frd\n",
      "frn\n",
      "new\n",
      "mea\n",
      "bsl\n",
      "tuc\n",
      "ott\n",
      "bou\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5573b633f94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGenerateTrainingSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-4434be76c617>\u001b[0m in \u001b[0;36mGenerateTrainingSet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mResizeForPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         RemoveDefectiveStation(indicatorVariationArrayLocalTime)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mReconstructedArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictIndicatorForAllLatitudes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicatorVariationArrayLocalTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquietDays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartDateMatlab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-2dc83ee2a341>\u001b[0m in \u001b[0;36mPredictIndicatorForAllLatitudes\u001b[0;34m(baseArray)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for all degrees in longitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if the current point in the matrix is a nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mspecificLatitudeTimePrediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetIndicatorLongPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelTuned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictionArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start the Machine Learning algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mpredictionArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecificLatitudeTimePrediction\u001b[0m \u001b[0;31m# add the predicted values to the global prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictionArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-034b5e0dc52e>\u001b[0m in \u001b[0;36mGetIndicatorLongPrediction\u001b[0;34m(latitude, longitude, params, baseArray)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemoveNan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPolyRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# return the result of the PolyRegression def, defined below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-6add5e3ae422>\u001b[0m in \u001b[0;36mPolyRegression\u001b[0;34m(latValues, indicatorValues, params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPolyRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicatorValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpoly_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpoly_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpoly_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicatorValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoly_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# 3. Step parameters and other initilisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mParameter\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m_get_params\u001b[0;34m(self, attr, deep)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Unbound method: the first parameter becomes positional-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36mfrom_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m--> 541\u001b[0;31m                                         kind=_POSITIONAL_OR_KEYWORD))\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# ... w/ defaults.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation, _partial_kwarg)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_POSITIONAL_ONLY\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[a-z_]\\w*$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{0!r} is not a valid parameter name'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[1;32m    140\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GenerateTrainingSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RemoveDefectiveStation(`numpy.array`)\n",
    "Takes as input the matrix we are working with and replace by nans all the axis with a `mean_squared_error` too far from the `mean_squared_error` of the mean of all the axis.\n",
    "\n",
    "This `def` allows us to considere as non-existant all the stations outputing delusional data. For example, the green line in the middle of the matrix below represents a station outputing zeros for the entire day straight, this `def` will alow us to take it off.\n",
    "\n",
    "\n",
    "<img src=\"Notebook_images/DelusionalDataGreen.jpg\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveDefectiveStation(array):\n",
    "    rmseRef = np.array([])\n",
    "    rmseRefIndex = np.array([])\n",
    "    for i in range(array.shape[0]):\n",
    "        if not math.isnan(np.sum(array[i])):\n",
    "            rmseRefIndex = np.append(rmseRefIndex, i)\n",
    "            rmseRef = np.append(rmseRef, mean_squared_error(np.nanmean(array, axis=0), array[i]))\n",
    "    array[np.int16(rmseRefIndex[np.argmax(rmseRef)])] = np.full(array.shape[1], np.nan)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RequestMatlab()\n",
    "Stores all the `indices_alpha` output in a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RequestMatlab():\n",
    "    global startDateMatlab, endDateMatlab, startDate, endDate, year, month, day\n",
    "    for i in range(0,allStationCodes.shape[0]): \n",
    "        if allStationLatgeos[i]>latMin and allStationLatgeos[i]<latMax:\n",
    "            try:\n",
    "                stationsOut[allStationCodes[i]] = eng.indices_alpha(matlab.double(startDateMatlab), matlab.double(endDateMatlab),str(allStationCodes[i]))\n",
    "            except:\n",
    "                stationsNonexistentInFolder.append(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IndicatorCalculation(`Dict`, `float`, `datetime.datetime`, `float`)\n",
    "Retrieves from `stationsOut` the variation of the indice we chose for a given station in order to create `stationIndicatorVariation` and returns it.\n",
    "\n",
    "Returns also the difference as a percentage between the station's magnetic vector magnitude and `igrf`. Allowing us to create our weighting system.\n",
    "\n",
    "The weight calculation is implemented as follow:\n",
    "$$\\frac{\\sqrt{x1^2 + y1^2 + z1^2}}{\\beta}$$\n",
    "with $Î²$ the magnitude of `igrf` for the given time and station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndicatorCalculation(dataSt, timeshift, currentDate, igrf):\n",
    "    \n",
    "    x1=np.float32(dataSt.get(\"x1\")[timeshift])\n",
    "    y1=np.float32(dataSt.get(\"y1\")[timeshift])\n",
    "    y2=np.float32(dataSt.get(\"y2\")[timeshift])\n",
    "    z1=np.float32(dataSt.get(\"z1\")[timeshift])\n",
    "    ratio = ((math.sqrt(pow(x1, 2)+pow(y1, 2)+pow(z1, 2)))/igrf)\n",
    "    return np.round(y2,10), ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CalculateIGRF(`Dict`, `datetime.datetime`)\n",
    "Requests `matlab.igrf()` and returns the fourth output to get the magnitude of `igrf`\n",
    "\n",
    "*Note:* The `nargout=4` in the below code: \n",
    "```python\n",
    "b=eng.igrf(matlab.double([stLongeo]), matlab.double([stLatgeo]), matlab.double([stAlt]), matlab.double([currentDateMatlab]), nargout=4)\n",
    "```\n",
    "notifies python that Matlab is going to output 4 results and all of them has to be taken in account. By default, when dealing with multiple outputs, python only stores the last of them. So the `b` variable in the line above will be an array and not a single float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateIGRF(dataSt, currentDate):    \n",
    "    stLongeo=np.float32(dataSt.get(\"longeo\"))\n",
    "    stLatgeo=np.float32(dataSt.get(\"latgeo\"))\n",
    "    stAlt=np.float32(dataSt.get(\"alt\"))\n",
    "    \n",
    "    currentDateMatlab = [currentDate.year, currentDate.month, currentDate.day, currentDate.hour, currentDate.minute, currentDate.second]\n",
    "    b=eng.igrf(matlab.double([stLongeo]), matlab.double([stLatgeo]), matlab.double([stAlt]), matlab.double([currentDateMatlab]), nargout=4)\n",
    "    return b[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MakeStationIndicatorVariation()\n",
    "Fills `stationIndicatorVariation` and `stationIndicatorRatioVariation` containing a single indice type and the `igrf` ratio for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeStationIndicatorVariation():\n",
    "    \n",
    "    global stationIndicatorVariation\n",
    "    global stationIndicatorRatioVariation\n",
    "    global stationIndicatorVariation\n",
    "    global numberOfMinutesNeededInTheTimeStamp\n",
    "    global timeBetweenValues\n",
    "    global numberOfValues\n",
    "    global latMin\n",
    "    global latMax\n",
    "    \n",
    "    stationIndicatorRatioVariation = defaultdict(list)\n",
    "    stationIndicatorVariation.clear()\n",
    "    numberOfMinutesNeededInTheTimeStamp = 1440*numberOfDaysWithData\n",
    "    timeBetweenValues = 10\n",
    "    numberOfValues = np.int16(numberOfMinutesNeededInTheTimeStamp/timeBetweenValues)\n",
    "    for st in stationsOut.keys():\n",
    "        if stationsOut[st]:\n",
    "            if stationsOut[st].get(\"latgeo\") > latMin and stationsOut[st].get(\"latgeo\") < latMax:\n",
    "                igrf=CalculateIGRF(stationsOut[st], startDate)\n",
    "                delta = endDate-startDate\n",
    "                totalMinutes = (delta.total_seconds()+1)/60\n",
    "                for i in range(0, np.int16(totalMinutes), timeBetweenValues):\n",
    "                    try:\n",
    "                        update = datetime.timedelta(minutes=i)\n",
    "                        currentDate = startDate+update\n",
    "                        magneticValue, ratio = IndicatorCalculation(stationsOut.get(st), i, currentDate, igrf)\n",
    "                        stationIndicatorVariation[st].append(magneticValue)\n",
    "                        stationIndicatorRatioVariation[st].append(ratio)\n",
    "                    except:\n",
    "                        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalizeWithGivenBounds(`numpy.array`, `numpy.array`)\n",
    "Normalizes all the values of a vector between the wanted bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeWithGivenBounds(values, bounds):\n",
    "    return [bounds['desired']['lower'] + (x - bounds['actual']['lower']) * (bounds['desired']['upper'] - bounds['desired']['lower']) / (bounds['actual']['upper'] - bounds['actual']['lower']) for x in values]               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ManuallyNormalizeData01()\n",
    "Applyes the ratio to the values by multiplying `stationIndicatorVariation` with `stationIndicatorRatioVariation`. Just comment lines 37 and 38 to disable the weighting system.\n",
    "\n",
    "Uses `normalizeWithGivenBounds` on all the stations contained in `stationIndicatorVariation` to scale the data and store everyting in `normalized01StationIndicatorVariation`\n",
    "\n",
    "This `def` fills also the maximum and minimum values in the matrix before rescaling everything, allowing us to rescale them to their default values when nedeed. (does the same process for the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ManuallyNormalizeData01():\n",
    "    global normalized01StationIndicatorVariation\n",
    "    global maxValueinDataset\n",
    "    global minValueinDataset\n",
    "    normalized01StationIndicatorVariation = defaultdict(list)\n",
    "    maxValueinDataset=0\n",
    "    minValueinDataset=0\n",
    "    max_values = np.array([])\n",
    "    min_values = np.array([])\n",
    "    max_values_ratio = np.array([])\n",
    "    min_values_ratio = np.array([])\n",
    "    \n",
    "    for st in stationsOut.keys():\n",
    "        if stationIndicatorVariation[st]:\n",
    "            if not math.isnan(stationIndicatorVariation[st][0]):\n",
    "                max_values = np.append(max_values, max(stationIndicatorVariation[st])) \n",
    "                min_values = np.append(min_values, min(stationIndicatorVariation[st]))\n",
    "                max_values_ratio = np.append(max_values_ratio, max(stationIndicatorRatioVariation[st])) \n",
    "                min_values_ratio = np.append(min_values_ratio, min(stationIndicatorRatioVariation[st])) \n",
    "    totalMax = max(max_values)\n",
    "    totalMin = min(min_values)\n",
    "    totalMaxRatio = max(max_values_ratio)\n",
    "    totalMinRatio = min(min_values_ratio)\n",
    "    maxValueinDataset = totalMax\n",
    "    minValueinDataset = totalMin\n",
    "    \n",
    "    bounds = np.array([0,1])   \n",
    "    boundsRatio = np.array([-1,1])   \n",
    "    for st in stationsOut.keys():\n",
    "        if stationIndicatorVariation[st]:\n",
    "            localMax = max(stationIndicatorVariation[st])\n",
    "            localMin = min(stationIndicatorVariation[st])\n",
    "            localMaxRatio = max(stationIndicatorRatioVariation[st])\n",
    "            localMinRatio = min(stationIndicatorRatioVariation[st])\n",
    "            \n",
    "            IndicatorVariationAppliedRatio=stationIndicatorVariation.copy()\n",
    "            for i in range(0, len(stationIndicatorVariation[st])):\n",
    "                IndicatorVariationAppliedRatio[st][i] = stationIndicatorVariation[st][i]*stationIndicatorRatioVariation[st][i]\n",
    "            normalized01StationIndicatorVariation[st] = normalizeWithGivenBounds(np.array(IndicatorVariationAppliedRatio[st]), {'actual': {'lower': totalMin, 'upper': totalMax}, 'desired': {'lower': bounds[0], 'upper': bounds[1]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexValueOnLocalTime(`numpy.array`, `str`, `int`)\n",
    "Converts a station's longitude in minutes (assuming 1 degree = 4 minutes) related to Greenwich and shifts back everything to the reference to have arrays representing data in local time.\n",
    "\n",
    "Example of the effect of `indexValueOnLocalTime` on `stationName = clf` (not far away from Greenwich):\n",
    "\n",
    "<img src=\"Notebook_images/VariationUTC_LocalTime.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexValueOnLocalTime(array, stationName, i):\n",
    "    numberOfValuesLong = array.shape[1]\n",
    "    localTimeValuesArray = np.full((180, numberOfValuesLong), np.nan)\n",
    "    long = float(stationsOut[stationName].get(\"longeo\"))\n",
    "    shiftValues = np.round((long*4)/timeBetweenValues,0)\n",
    "    initialShiftValues = shiftValues\n",
    "    decreasingIndex=0\n",
    "    increasingIndex=0\n",
    "    for y in range(np.int16(numberOfValues/numberOfDaysWithData),numberOfValues):\n",
    "        if y+shiftValues>=array.shape[1]:\n",
    "            localTimeValuesArray[i][np.int16(y-(y-shiftValues))-decreasingIndex] = array[i][np.int16(numberOfValues/numberOfDaysWithData)-decreasingIndex]\n",
    "            decreasingIndex+=1\n",
    "        else:\n",
    "            localTimeValuesArray[i][np.int16(y-y+shiftValues+increasingIndex)] = array[i][y]\n",
    "            increasingIndex+=1\n",
    "            \n",
    "    return localTimeValuesArray[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### makeIndicatorVariationArray()\n",
    "Fills `indicatorVariationArray` (UTC) and `indicatorVariationArrayLocalTime` (LT) which are the final versions we will contruct the dataSet on. They are `numpy.array` each rows corresponding to a latitude included between `latMax` and `latMin` with an axis=0 lenght equals to 1440/`timeBetweenValues` (1440 being the number of minutes in one day). in the current state of the art the shape of the arrays is (24,144), 24 = `latMax` - `latMin` and 144 = 1440 / `timeBetweenValues` with timeBetweenValues = 10 and 1440 = the number of minutes in 24h.\n",
    "\n",
    "__When the `def` encounters two stations located at the same latitude, it automatically overwrite a station with the closest one to Greenwich.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeIndicatorVariationArray():\n",
    "    global indicatorVariationArray\n",
    "    global indicatorVariationArrayLocalTime\n",
    "      \n",
    "    # LINUX\n",
    "    # indicatorVariationArray = np.full((180, len(normalized01StationIndicatorVariation[normalized01StationIndicatorVariation.keys()[1]])), np.nan)\n",
    "    # WINDOWS\n",
    "    indicatorVariationArray = np.full((180, len(normalized01StationIndicatorVariation[list(normalized01StationIndicatorVariation.keys())[1]])), np.nan)\n",
    "    localIndicatorVariationArray = np.full_like(indicatorVariationArray, np.nan)\n",
    "    # LINUX\n",
    "    # indicatorVariationArrayLocalTime = np.full((180, len(normalized01StationIndicatorVariation[normalized01StationIndicatorVariation.keys()[1]])), np.nan)\n",
    "    # localNormalized01StationIndicatorVariation = np.full((180, len(normalized01StationIndicatorVariation[normalized01StationIndicatorVariation.keys()[1]])), np.nan)\n",
    "    # WINDOWS\n",
    "    indicatorVariationArrayLocalTime = np.full((180, len(normalized01StationIndicatorVariation[list(normalized01StationIndicatorVariation.keys())[1]])), np.nan)\n",
    "    localNormalized01StationIndicatorVariation = np.full((180, len(normalized01StationIndicatorVariation[list(normalized01StationIndicatorVariation.keys())[1]])), np.nan)\n",
    "    \n",
    "    stationsPerLat = defaultdict(list)\n",
    "    intermediateLocalIndicatorVariationArray = np.empty_like(localIndicatorVariationArray)\n",
    "    intermediateLocalNormalized01StationIndicatorVariation = np.empty_like(localNormalized01StationIndicatorVariation)\n",
    "    alreadyFilled = False\n",
    "    for st in stationsOut.keys():\n",
    "        alreadyFilled=False\n",
    "        for i in range(latMin, latMax):\n",
    "            if not isinstance(stationsOut[st], matlab.double):\n",
    "            # if not isinstance(stationsOut[st], matlab.mlarray.double):\n",
    "                if i == np.round(np.int16(stationsOut[st].get(\"latgeo\")),0):\n",
    "                    if stationsOut[st].get('longeo')<307 and stationsOut[st].get('longeo')>240:\n",
    "                        stationsPerLat[i+90].append(st)\n",
    "                        if len(stationsPerLat[i+90])>1:\n",
    "                            alreadyFilled=True\n",
    "                            if normalized01StationIndicatorVariation[st]:\n",
    "                                if alreadyFilled==True:\n",
    "                                    stName = stationsPerLat[i+90][stationsPerLat[i+90].index(min(stationsPerLat[i+90]))-1]\n",
    "                                    localIndicatorVariationArray[i+90] = normalized01StationIndicatorVariation[stName]\n",
    "                                    localNormalized01StationIndicatorVariation[i+90] = normalized01StationIndicatorVariation[stName]\n",
    "                                    indicatorVariationArrayLocalTime[i+90] = indexValueOnLocalTime(localNormalized01StationIndicatorVariation, stName, i+90)\n",
    "                                    indicatorVariationArray[i+90] = localIndicatorVariationArray[i+90]\n",
    "                                else:\n",
    "                                    localIndicatorVariationArray[i+90] = normalized01StationIndicatorVariation[st]\n",
    "                                    localNormalized01StationIndicatorVariation[i+90] = normalized01StationIndicatorVariation[st]\n",
    "                                    indicatorVariationArrayLocalTime[i+90] = indexValueOnLocalTime(localNormalized01StationIndicatorVariation, st, i+90)\n",
    "                                    indicatorVariationArray[i+90] = localIndicatorVariationArray[i+90]\n",
    "                        else: \n",
    "                            if len(stationIndicatorVariation[st])!=0:\n",
    "                                indicatorVariationArray[i+90]=stationIndicatorVariation[st]\n",
    "                                indicatorVariationArrayLocalTime[i+90] = indexValueOnLocalTime(indicatorVariationArray, st, i+90)\n",
    "                            else:\n",
    "                                None\n",
    "                else:\n",
    "                    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResizeForPlot()\n",
    "Because we are using one more day to the right and to the left to have enough space for `indexValueOnLocalTime()`, this `def` cuts the additional days to keep the one we are interrested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeForPlot():\n",
    "    global indicatorVariationArrayLocalTime\n",
    "    global indicatorVariationArray\n",
    "    indicatorVariationArrayResized = np.empty([latMax-latMin, np.int16(numberOfValues-((numberOfValues/numberOfDaysWithData)*2))])\n",
    "    indicatorVariationArrayLocalTimeResized = np.empty([latMax-latMin, np.int16(numberOfValues-((numberOfValues/numberOfDaysWithData)*2))])\n",
    "    m=0\n",
    "    for i in range(latMin+90, latMax+90):\n",
    "        a=0\n",
    "        for y in range(np.int16(numberOfValues/numberOfDaysWithData),np.int16(numberOfValues-(numberOfValues/numberOfDaysWithData))):\n",
    "            indicatorVariationArrayResized[m][a]=indicatorVariationArray[i][y]\n",
    "            a+=1\n",
    "        m+=1\n",
    "    indicatorVariationArray = np.empty_like(indicatorVariationArrayResized)\n",
    "    indicatorVariationArray=indicatorVariationArrayResized[:]\n",
    "    m=0\n",
    "    for i in range(latMin+90, latMax+90):\n",
    "        a=0\n",
    "        for y in range(np.int16(numberOfValues/numberOfDaysWithData),np.int16(numberOfValues-(numberOfValues/numberOfDaysWithData))):\n",
    "            indicatorVariationArrayLocalTimeResized[m][a]=indicatorVariationArrayLocalTime[i][y]\n",
    "            a+=1\n",
    "        m+=1\n",
    "    indicatorVariationArrayLocalTime = np.empty_like(indicatorVariationArrayLocalTimeResized)\n",
    "    indicatorVariationArrayLocalTime=indicatorVariationArrayLocalTimeResized[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PredictIndicatorForAllLatitudesdes(`numpy.array`)\n",
    "\n",
    "Main Machine Learning function that triggers the polynomial regression for all longitude degrees.\n",
    "\n",
    "We want to train deep learning algorithms on full matrices to test their ability to reconstruct data in controled situations. Therefore, we will be able reproduce the behaviour of the magnetic field in any contextual circumstances. Consequently, the objective here is to do a preliminary reconstruction on highly covered areas like Europe to feed the deep learning algorithms with matrices without any `nan`.\n",
    "\n",
    "The `def` takes all the points from all working stations between two latitude bounds, removes the `nan` values for latitudes we don't have data and fits a polynomial regression on the remaining points. The result will be a matrix with the same dimension as the previous one but with all the blank lines filled.\n",
    "\n",
    "The below plot shows an example of retrieving all the stations point for a given longitude and a polynomial fit to fill any blank area:\n",
    "\n",
    "<img src=\"Notebook_images/figPrintModelFitForGivenLong.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "This process allows us to make a solid preliminary reconstruction like the one below:\n",
    "\n",
    "Starting from this matrix : <img src=\"Notebook_images/groundTruth.png\" alt=\"drawing\" width=\"300\"/> the reconstruction outputs this result: <img src=\"Notebook_images/groundTruthML.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictIndicatorForAllLatitudes(baseArray):\n",
    "    latsWithoutData = np.array([])\n",
    "    predictionArray = np.empty_like(baseArray)\n",
    "    predictionArray=np.copy(baseArray)\n",
    "    modelTuned = {'polynomialfeatures__degree': 2, 'linearregression__fit_intercept': True, 'linearregression__normalize': True}\n",
    "    for i in range(0,baseArray.shape[0]): # for all degrees in latitude\n",
    "        specificLatitudeTimePrediction = np.full(baseArray.shape[1], np.nan)\n",
    "        if math.isnan(np.sum(baseArray[i])): # is there any nan in the selected latitude ?\n",
    "            latsWithoutData = np.append(latsWithoutData, i+latMin) # if yes, add it to the empty latitudes list \n",
    "            for y in range(0,baseArray.shape[1]): # for all degrees in longitude\n",
    "                if (math.isnan(baseArray[i][y])):  # if the current point in the matrix is a nan\n",
    "                    specificLatitudeTimePrediction[y] = GetIndicatorLongPrediction(i,y,modelTuned,predictionArray) # start the Machine Learning algorithm  \n",
    "            predictionArray[i] = specificLatitudeTimePrediction # add the predicted values to the global prediction\n",
    "    return predictionArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GetIndicatorLongPrediction(`int`,`int`, `dict`, `numpy.array`)\n",
    "\n",
    "Gets the point of all stations at a given moment in time, concatenates them and removes the nan values. (ML algorithm don't allow nan values).\n",
    "This `def` takes as input a dictionary of parameters, which are hard coded at line 5 of `PredictIndicatorForAllLatitudes`.\n",
    "Before, I was doing parameters tuning at each training to fit the data as best as possible. But it appeared through tests that most of the time the parameters resulting from the process were always the same:\n",
    "```python\n",
    "{'polynomialfeatures__degree': 2, 'linearregression__fit_intercept': True, 'linearregression__normalize': True}\n",
    "```\n",
    "To gain processing time, this functionality is disabled by default. It can be enabled by replacing `modelTuned` allocation with the `ParametersTuningPoly(numpy.array,int)` function, which outputs a dictionary of parameters resulted from the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetIndicatorLongPrediction(latitude,longitude, params, baseArray):\n",
    "    indicatorLatVariation = np.array([])\n",
    "    for i in range(0, baseArray.shape[0]):\n",
    "        indicatorLatVariation = np.append(indicatorLatVariation, baseArray[i][longitude])\n",
    "    y = np.array(indicatorLatVariation)\n",
    "    x = np.arange(0, baseArray.shape[0], 1)\n",
    "    x,y = RemoveNan(x, y)\n",
    "    return PolyRegression(x,y,params).predict(np.array(latitude).reshape(1,-1)) # return the result of the PolyRegression def, defined below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RemoveNan(`numpy.array`, `numpy.array`)\n",
    "\n",
    "Takes as input all the indice values corresponding to each latitudes of the matrix, detects where there are nans and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveNan(latValues, indicatorValues):\n",
    "    indexDeleteY = np.array([])\n",
    "    for i in range(0, indicatorValues.shape[0]):\n",
    "        if math.isinf(indicatorValues[i]) or math.isnan(indicatorValues[i]):\n",
    "            indexDeleteY = np.append(indexDeleteY, i)\n",
    "    newY = np.delete(indicatorValues, indexDeleteY)\n",
    "    newX = np.delete(latValues, indexDeleteY)\n",
    "    newY=newY.reshape(newY.shape[0],1)\n",
    "    newX=newX.reshape(newY.shape[0],1)\n",
    "    \n",
    "    return newX, newY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PolyRegression(`numpy.array`, `numpy.array`, `Dict`)\n",
    "\n",
    "Makes a polynomial regression. `poly_grid.fit(X,Y)` where `X` is the latitude and `Y` is the indice.\n",
    "The `PolynomialRegression()` definition is custom and detailed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyRegression(latValues, indicatorValues, params):\n",
    "    poly_grid = PolynomialRegression()\n",
    "    poly_grid.set_params(**params)\n",
    "    poly_grid.fit(latValues, indicatorValues)\n",
    "    return poly_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PolynomialRegression(int, **)\n",
    "\n",
    "Makes a python pipeline out of `sklearn.preprocessing.PolynomialFeatures` and `sklearn.linear_model.LinearRegression`. This allows us to use a linear regression algorithm on a non-linear fit, giving as parameter the polynom's degree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParametersTuningPoly(`numpy.array`,`int`)\n",
    "\n",
    "Makes a quick fit on a given array of data to evaluate the best parameters on the current set. We are testing polynomial degrees from 2 to 5 and check if we should use `linearregression__fit_intercept` or `linearregression__normalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParametersTuningPoly(baseArray,long):\n",
    "    indicatorLatVariation = np.array([])\n",
    "    for i in range(0, baseArray.shape[0]):\n",
    "        indicatorLatVariation = np.append(indicatorLatVariation, baseArray[i][np.int16(long)])\n",
    "    y = np.array(indicatorLatVariation)\n",
    "    x = np.arange(0, baseArray.shape[0], 1)\n",
    "    x, y = RemoveNan(x, y)\n",
    "    \n",
    "    paramsTuning = {'polynomialfeatures__degree': [2,5], 'linearregression__fit_intercept': [True, False], 'linearregression__normalize': [True, False]}\n",
    "    poly_gridTuning = GridSearchCV(PolynomialRegression(), paramsTuning, cv=10, scoring='r2', verbose=0)\n",
    "    poly_gridTuning.fit(x, y)\n",
    "    return poly_gridTuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4eba9a92238e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGenerateTrainingSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# launch the main def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-6f4067bd8123>\u001b[0m in \u001b[0;36mGenerateTrainingSet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmakeIndicatorVariationArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mResizeForPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mRemoveDefectiveStation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicatorVariationArrayLocalTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mReconstructedArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictIndicatorForAllLatitudes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicatorVariationArrayLocalTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquietDays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b50c0bf07134>\u001b[0m in \u001b[0;36mRemoveDefectiveStation\u001b[0;34m(array)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mrmseRefIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmseRefIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mrmseRef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmseRef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmseRefIndex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmseRef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "GenerateTrainingSet() # launch the main def"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 matlab",
   "language": "python",
   "name": "dlwp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
